<!doctype html><html lang=en><head><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=referrer content="no-referrer"><meta name=description content="Slowly but steadily NVIDIA has been rotating in Maxwell GPUs into the companys lineup of Tesla server cards. Though Maxwell is not well-suited towards the kind of high precision HPC work that the Tesla lineup was originally crafted for, Maxwell is plenty suitable for just about every other server use NVIDIA can think of. And"><meta name=robots content="index,follow,noarchive"><link href="https://fonts.googleapis.com/css?family=Open+Sans:400|Old+Standard+TT:400&display=swap" rel=stylesheet media=print type=text/css onload='this.media="all"'><title>NVIDIA Announces Tesla M40 &amp;amp; M4 Server Cards</title><link rel=canonical href=./nvidia-announces-tesla-m40-m4-server-cards-data-center-machine-learning.html><style>*{border:0;font:inherit;font-size:100%;vertical-align:baseline;margin:0;padding:0;color:#000;text-decoration-skip:ink}body{font-family:open sans,myriad pro,Myriad,sans-serif;font-size:17px;line-height:160%;color:#1d1313;max-width:700px;margin:auto}p{margin:20px 0}a img{border:none}img{margin:10px auto;max-width:100%;display:block}.left-justify{float:left}.right-justify{float:right}pre,code{font:12px Consolas,liberation mono,Menlo,Courier,monospace;background-color:#f7f7f7}code{font-size:12px;padding:4px}pre{margin-top:0;margin-bottom:16px;word-wrap:normal;padding:16px;overflow:auto;font-size:85%;line-height:1.45}pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:0 0;border:0}pre code{display:inline;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}pre code::before,pre code::after{content:normal}em,q,em,dfn{font-style:italic}.sans,html .gist .gist-file .gist-meta{font-family:open sans,myriad pro,Myriad,sans-serif}.mono,pre,code,tt,p code,li code{font-family:Menlo,Monaco,andale mono,lucida console,courier new,monospace}.heading,.serif,h1,h2,h3{font-family:old standard tt,serif}strong{font-weight:600}q:before{content:"\201C"}q:after{content:"\201D"}del,s{text-decoration:line-through}blockquote{font-family:old standard tt,serif;text-align:center;padding:50px}blockquote p{display:inline-block;font-style:italic}blockquote:before,blockquote:after{font-family:old standard tt,serif;content:'\201C';font-size:35px;color:#403c3b}blockquote:after{content:'\201D'}hr{width:40%;height:1px;background:#403c3b;margin:25px auto}h1{font-size:35px}h2{font-size:28px}h3{font-size:22px;margin-top:18px}h1 a,h2 a,h3 a{text-decoration:none}h1,h2{margin-top:28px}#sub-header,.date{color:#403c3b;font-size:13px}#sub-header{margin:0 4px}#nav h1 a{font-size:35px;color:#1d1313;line-height:120%}.posts_listing a,#nav a{text-decoration:none}li{margin-left:20px}ul li{margin-left:5px}ul li{list-style-type:none}ul li:before{content:"\00BB \0020"}#nav ul li:before,.posts_listing li:before{content:'';margin-right:0}#content{text-align:left;width:100%;font-size:15px;padding:60px 0 80px}#content h1,#content h2{margin-bottom:5px}#content h2{font-size:25px}#content .entry-content{margin-top:15px}#content .date{margin-left:3px}#content h1{font-size:30px}.highlight{margin:10px 0}.posts_listing{margin:0 0 50px}.posts_listing li{margin:0 0 25px 15px}.posts_listing li a:hover,#nav a:hover{text-decoration:underline}#nav{text-align:center;position:static;margin-top:60px}#nav ul{display:table;margin:8px auto 0}#nav li{list-style-type:none;display:table-cell;font-size:15px;padding:0 20px}#links{display:flex;justify-content:space-between;margin:50px 0 0}#links :nth-child(1){margin-right:.5em}#links :nth-child(2){margin-left:.5em}#not-found{text-align:center}#not-found a{font-family:old standard tt,serif;font-size:200px;text-decoration:none;display:inline-block;padding-top:225px}@media(max-width:750px){body{padding-left:20px;padding-right:20px}#nav h1 a{font-size:28px}#nav li{font-size:13px;padding:0 15px}#content{margin-top:0;padding-top:50px;font-size:14px}#content h1{font-size:25px}#content h2{font-size:22px}.posts_listing li div{font-size:12px}}@media(max-width:400px){body{padding-left:20px;padding-right:20px}#nav h1 a{font-size:22px}#nav li{font-size:12px;padding:0 10px}#content{margin-top:0;padding-top:20px;font-size:12px}#content h1{font-size:20px}#content h2{font-size:18px}.posts_listing li div{font-size:12px}}@media(prefers-color-scheme:dark){*,#nav h1 a{color:#fdfdfd}body{background:#121212}pre,code{background-color:#262626}#sub-header,.date{color:#bababa}hr{background:#ebebeb}}</style></head><body><section id=nav><h1><a href=./index.html>WebBlog</a></h1><ul><li><a href=./index.xml>Rss</a></li><li><a href=./sitemap.xml>Sitemap</a></li></ul></section><section id=content><h1>NVIDIA Announces Tesla M40 &amp;amp; M4 Server Cards</h1><div id=sub-header>June 2024 · 5 minute read</div><div class=entry-content><p>Slowly but steadily NVIDIA has been rotating in Maxwell GPUs into the company’s lineup of Tesla server cards. Though Maxwell is not well-suited towards the kind of high precision HPC work that the Tesla lineup was originally crafted for, Maxwell is plenty suitable for just about every other server use NVIDIA can think of. And as a result the company has been launching what’s best described as new breeds of Maxwell cards in the last few months.</p><p>After <a href=#>August’s announcement of the Tesla M60 and M6 cards</a> – with a focus on VDI and video encoding – NVIDIA is back today for the announcement of the next set of Tesla cards, the M40 and the M4. In what the company is dubbing their “hyperscale accelerators,” NVIDIA is launching these two cards with a focus on capturing a larger portion of the machine learning market.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9776/T5_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><table align=center border=0 cellpadding=0 cellspacing=1 width=650><tbody readability=1><tr class=tgrey readability=2><td align=center colspan=7>NVIDIA Tesla Family Specification Comparison</td></tr><tr class=tlblue><td width=140>&nbsp;</td><td align=center valign=middle width=126>Tesla M40</td><td align=center valign=middle width=126>Tesla M4</td><td align=center valign=middle width=126>Tesla M60</td><td align=center valign=middle width=126>Tesla K40</td></tr><tr><td class=tlgrey>Stream Processors</td><td align=center valign=middle>3072</td><td align=center valign=middle>1024</td><td align=center valign=middle>2 x 2048<br>(4096)</td><td align=center valign=middle>2880</td></tr><tr><td class=tlgrey>Boost Clock(s)</td><td align=center valign=middle>~1140MHz</td><td align=center valign=middle>~1075MHz</td><td align=center valign=middle>~1180MHz</td><td align=center valign=middle>810MHz, 875MHz</td></tr><tr><td class=tlgrey>Memory Clock</td><td align=center valign=middle>6GHz GDDR5</td><td align=center valign=middle>5.5GHz GDDR5</td><td align=center valign=middle>5GHz GDDR5</td><td align=center valign=middle>6GHz GDDR5</td></tr><tr><td class=tlgrey>Memory Bus Width</td><td align=center valign=middle>384-bit</td><td align=center valign=middle>128-bit</td><td align=center valign=middle>2 x 256-bit</td><td align=center valign=middle>384-bit</td></tr><tr><td class=tlgrey>VRAM</td><td align=center valign=middle>12GB</td><td align=center valign=middle>4GB</td><td align=center valign=middle>2 x 8GB<br>(16GB)</td><td align=center valign=middle>12GB</td></tr><tr><td class=tlgrey>Single Precision (FP32)</td><td align=center valign=middle>7 TFLOPS</td><td align=center valign=middle>2.2 TFLOPS</td><td align=center valign=middle>9.7 TFLOPS</td><td align=center valign=middle>4.29 TFLOPS</td></tr><tr><td class=tlgrey>Double Precision (FP64)</td><td align=center valign=middle>0.21 TFLOPS (1/32)</td><td align=center valign=middle>0.07 TFLOPS (1/32)</td><td align=center valign=middle>0.3 TFLOPS (1/32)</td><td align=center valign=middle>1.43 TFLOPS (1/3)</td></tr><tr><td class=tlgrey>Transistor Count</td><td align=center valign=middle>8B</td><td align=center valign=middle>2.94B</td><td align=center valign=middle>2x 5.2B</td><td align=center valign=middle>7.1B</td></tr><tr><td class=tlgrey>TDP</td><td align=center valign=middle>250W</td><td align=center valign=middle>50W-75W</td><td align=center valign=middle>225W-300W</td><td align=center valign=middle>235W</td></tr><tr><td class=tlgrey>Cooling</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Passive<br>(Low Profile)</td><td align=center valign=middle>Active/Passive</td><td align=center valign=middle>Active/Passive</td></tr><tr><td class=tlgrey>Manufacturing Process</td><td align=center valign=middle>TSMC 28nm</td><td align=center valign=middle>TSMC 28nm</td><td align=center valign=middle>TSMC 28nm</td><td align=center valign=middle>TSMC 28nm</td></tr><tr><td class=tlgrey>GPU</td><td align=center valign=middle>GM200</td><td align=center valign=middle>GM206</td><td align=center valign=middle>GM204</td><td align=center valign=middle>GK110</td></tr><tr><td class=tlgrey>Target Market</td><td align=center valign=middle>Machine Learning</td><td align=center valign=middle>Machine Learning</td><td align=center valign=middle>VDI</td><td align=center valign=middle>Compute</td></tr></tbody></table><p>First let’s quickly talk about the cards themselves. The Tesla M40 marks the introduction of the GM200 GPU to the Tesla lineup, with NVIDIA looking to put their best single precision (FP32) GPU to good use. This is a 250 Watt full power and fully enabled GM200 card – though with Maxwell this distinction loses some meaning – with NVIDIA outfitting the card with 12GB of GDDR5 VRAM clocked at 6GHz. We know that Maxwell doesn’t support on-chip ECC for the RAM and caches, but it’s not clear at this time whether soft-ECC is supported for the VRAM. Otherwise, with the exception of the change in coolers this card is a spitting image of the consumer GeForce GTX Titan X.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9776/TeslaM40_Angle_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Joining the Tesla M40 is the Tesla M4. As hinted at by its single-digit product number, the M4 is a small, low powered card. In fact this is the first Tesla card to be released in a PCIe half-height low profile form factor, with NVIDIA specifically aiming for dense clusters of these cards. Tesla M4 is based on GM206 – this being the GPU’s first use in a Tesla product as well – and is paired with 4GB of GDDR5 clocked at 5GHz. NVIDIA offers multiple power/performance configurations of the M4 depending on server owner’s needs, ranging from 50W to 75W, with the highest power mode rated to deliver up to 2.2TFLOPS of FP32 performance.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9776/TeslaM4_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Both the Tesla M40 and M4 are being pitched at the machine learning market, which has been a strong focus for NVIDIA since the very start of the year. The company believes that machine learning is the next great frontier for GPUs, capitalizing on neural net research that has shown GPUs to be capable of both quickly training and quickly executing neural nets. Neural nets in turn are increasingly being used as more efficient means for companies to process vast amounts of audio & video data (e.g. the Facebooks of the world).</p><p>To that end we have seen the company focus on machine learning in the automotive sector with products such as the <a href=#>Drive PX</a> system and lay out their long-term plans for machine learning with the forthcoming Pascal architecture at <a href=#>GTC 2015</a>. In the interim then we have the Tesla M40 and Tesla M4 for building machine learning setups with NVIDIA’s current-generation architecture.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9776/T4_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Given their performance and power profiles, Tesla M40 and M4 are intended to split the machine learning market on the basis of training versus execution The powerful M40 being well-suited for quicker training of neural nets and other systems, while the more compact M4 is well-suited for dense clusters of systems actually executing various machine learning tasks. Note that it’s interesting that NVIDIA is pitching the M40 and not the more powerful M60 for training tasks; as NVIDIA briefly discussed among their long-term plans at GTC 2015, current training algorithms don’t scale very well beyond a couple of GPUs, so users are better off with a couple top-tier GM200 GPUs than a larger array of densely packed GM204 GPUs. As a result the M40 occupies an interesting position as the company’s top Tesla card for machine learning tasks that aren’t trivially scalable to many GPUs.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9776/T9_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Meanwhile, along with today’s hardware announcement NVIDIA is also announcing a new software suite to tie together their hyperscale ambitions. Dubbed the “NVIDIA Hyperscale Suite,” the company is putting together software targeted at end-user facing web services. Arguably the lynchpin of the suite is NVIDIA’s GPU REST Engine, a service for <a href=#>RESTful APIs</a> to utilize the GPU, and in turn allowing web services to easily access GPU resources. NVIDIA anticipates the GPU REST Engine enabling everything from search acceleration to image classification, and to start things off they are providing the NVIDIA Image Compute Engine, a REST-capable service for GPU image resizing. Meanwhile the company is also be providing their cuDNN neural net software as part of the suite, and versions of FFmpeg with support for NVIDIA’s hardware video encode and decode blocks to speed up video processing and transcoding.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9776/T10_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Wrapping things up, as is common with Tesla product releases, today’s announcements will predate the hardware itself by a bit. NVIDIA tells us that the Tesla M40 and the hyperscale software suite will be available later this year (with just over a month and a half remaining). Meanwhile the Tesla M4 will be released in Q1 of 2016. NVIDIA has not announced card pricing at this time.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZIZ4g5Vopa%2BhlJ6ubq3Np6auppOawG7AxKyjmmWdaX1uuZNmqp6qppq%2Fbq%2FAq5usZZSWwaJ5wp6lrZ2iYrqir8eipZ5lnJqus7rIp54%3D</p></div><div id=links><a href=./patti-stefani.html>&#171;&nbsp;Patti Stefani</a>
<a href=./meghan-markle-shares-archie-lilibet-halloween-costumes.html>Meghan Markle shares funny story about Archie and Lilibet's Halloween costumes&nbsp;&#187;</a></div></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>